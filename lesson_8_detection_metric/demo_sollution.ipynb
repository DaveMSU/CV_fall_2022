{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f28f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    res = {}\n",
    "    with open(filename) as fhandle:\n",
    "        reader = csv.DictReader(fhandle)\n",
    "        for row in reader:\n",
    "            res[row['filename']] = row['class']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a100d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv(\"/home/david_tyuman/my_github/cv_fall_2022/lesson_8_detection_metric/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8872d42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import typing as tp\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models\n",
    "\n",
    "from dataset import(\n",
    "    ImageClassifyDataset\n",
    ")\n",
    "from network import ClassifyNetwork\n",
    "\n",
    "\n",
    "EMBD_NUMBER_TO_SHOW = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c491352",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/learning_process/base.json') as f:\n",
    "    learning_process = json.load(f)\n",
    "params = learning_process[\"hyper_params\"][\"loss\"][\"params\"]\n",
    "if \"weight\" in params:\n",
    "    learning_process[\"hyper_params\"][\"loss\"][\"params\"][\"weight\"] = \\\n",
    "        torch.Tensor(list(params[\"weight\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e6c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb56c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageClassifyDatasetBalancedSampler(torch.utils.data.Sampler):\n",
    "#     class Iterator:\n",
    "#         def __init__(self, consumption: dict, quantile_class: int):\n",
    "#             self.consumption = consumption\n",
    "#             self.class_names = list(self.consumption)\n",
    "#             self._size = 0\n",
    "#             self._quantile_class = quantile_class\n",
    "            \n",
    "#         def __next__(self):\n",
    "#             if len(self.class_names) == 0:\n",
    "#                 self.class_names = list(self.consumption)\n",
    "#             class_name = self.class_names.pop()\n",
    "            \n",
    "#             nums_of_empty_dicts = len(\n",
    "#                 list(filter(lambda l: len(l) == 0, self.consumption.values()))\n",
    "#             )\n",
    "#             if nums_of_empty_dicts >= self._quantile_class:\n",
    "#                 raise StopIteration\n",
    "\n",
    "#             while len(self.consumption[class_name]) == 0:\n",
    "#                 class_name = self.class_names.pop()\n",
    "#             indx = self.consumption[class_name].pop()\n",
    "#             return indx\n",
    "            \n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             dataset: ImageClassifyDataset,\n",
    "#             quantile_class: int\n",
    "#     ):\n",
    "#         self._items_groups = dict(dataset._items_groups).copy()\n",
    "        \n",
    "#         self._distr = {\n",
    "#             class_name: len(indexes) / len(dataset)\n",
    "#                 for class_name, indexes in self._items_groups.items()\n",
    "#         }\n",
    "#         self._quantile_class = quantile_class\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         return self.Iterator(copy.deepcopy(self._items_groups), self._quantile_class)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         it_ = self.Iterator(copy.deepcopy(self._items_groups), self._quantile_class)\n",
    "#         len_ = 0\n",
    "#         try:\n",
    "#             while (i := next(it_)):\n",
    "#                 len_ += 1\n",
    "#         except StopIteration:\n",
    "#             pass\n",
    "#         return len_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a0448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f4d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = learning_process[\"dataset_params\"]\n",
    "val_type = dataset_params[\"val_type\"]\n",
    "train_fraction = dataset_params[\"train_fraction\"]\n",
    "output_classes_num = learning_process[\"network\"][\"output_classes_num\"]\n",
    "new_size = dataset_params[\"new_size\"]\n",
    "if dataset_params[\"augmentation\"] is None:\n",
    "    transforms = None\n",
    "else:\n",
    "    transforms = [\n",
    "        globals()[dict_[\"transform_type\"]](**dict_[\"params\"])\n",
    "            for dict_ in dataset_params[\"augmentation\"]\n",
    "    ]\n",
    "\n",
    "train_dataset = ImageClassifyDataset(\n",
    "    mode=\"train\",\n",
    "    val_type=val_type,\n",
    "    train_fraction=train_fraction,\n",
    "    root_folder=pathlib.Path('/home/david_tyuman/my_github/cv_fall_2022/lesson_8_detection_metric/cropped-train'),\n",
    "    classes_num=output_classes_num,\n",
    "    new_size=new_size,\n",
    "    transforms=transforms\n",
    ")\n",
    "\n",
    "val_dataset = ImageClassifyDataset(\n",
    "    mode=\"val\",\n",
    "    val_type=val_type,\n",
    "    train_fraction=train_fraction,\n",
    "    root_folder=pathlib.Path('/home/david_tyuman/my_github/cv_fall_2022/lesson_8_detection_metric/cropped-train'),\n",
    "    classes_num=output_classes_num,\n",
    "    new_size=new_size,\n",
    "    transforms=None\n",
    ")\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     dataset=train_dataset,\n",
    "#     batch_size = dataset_params[\"train_batch_size\"],\n",
    "#     sampler=ImageClassifyDatasetBalancedSampler(train_dataset, 20),\n",
    "#     drop_last=True\n",
    "# )\n",
    "\n",
    "# val_dataloader = DataLoader(\n",
    "#     dataset=val_dataset,\n",
    "#     batch_size = dataset_params[\"val_batch_size\"],\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size = dataset_params[\"train_batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size = dataset_params[\"val_batch_size\"],\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad5a159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71900, 7996)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe83c580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cda449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b44ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = learning_process[\"network\"]\n",
    "net = ClassifyNetwork(\n",
    "    base_net=getattr(models, network_params[\"base_net\"][\"type\"])(\n",
    "        **network_params[\"base_net\"][\"params\"]\n",
    "    ),\n",
    "    internal_features=network_params[\"internal_features\"],\n",
    "    output_classes_num=network_params[\"output_classes_num\"],\n",
    "    correct_priors=network_params[\"correct_priors\"]\n",
    ")\n",
    "\n",
    "loss_params = learning_process[\"hyper_params\"][\"loss\"]\n",
    "loss = getattr(torch.nn, loss_params[\"loss_type\"])(**loss_params[\"params\"])\n",
    "\n",
    "optimizer_params = learning_process[\"hyper_params\"][\"optimizer\"]\n",
    "optimizer = getattr(torch.optim, optimizer_params[\"optimizer_type\"])(\n",
    "    net.parameters(),\n",
    "    **optimizer_params[\"params\"]\n",
    ")\n",
    "\n",
    "epoch_nums = learning_process[\"hyper_params\"][\"epoch_nums\"]\n",
    "\n",
    "def _wrap_func(func: tp.Callable, params: dict) -> tp.Callable:\n",
    "    def _wrapper(*args, **kwargs):\n",
    "        kwargs.update(params)\n",
    "        return func(*args, **kwargs)\n",
    "    return _wrapper\n",
    "metrics = []\n",
    "for metric in learning_process[\"validation\"][\"metrics\"]:\n",
    "    metric_func = getattr(sklearn.metrics, metric[\"type\"])\n",
    "    _wraped_metric = _wrap_func(metric_func, metric[\"params\"])\n",
    "    metrics.append(\n",
    "        {\n",
    "            \"name\": metric[\"name\"],\n",
    "            \"prediction_type\": metric[\"prediction_type\"],\n",
    "            \"func\": _wraped_metric\n",
    "        }\n",
    "    )\n",
    "main_metric = learning_process[\"validation\"][\"main_metric\"]\n",
    "best_main_metric_value = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8e456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d3ffa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration(\n",
    "        y_probs: np.ndarray,\n",
    "        y_true: np.ndarray\n",
    "    ) -> tp.List[tp.Tuple[float, float]]:\n",
    "    y_pred = y_probs.argmax(axis=1)\n",
    "    y_max_probs = y_probs[range(y_true.shape[0]), y_pred]\n",
    "    results = (y_true == y_pred)\n",
    "    rez = [\n",
    "        (i + 0.025, np.mean(results[(i < y_max_probs) & (y_max_probs < (i + 0.05))]))\n",
    "            for i in np.linspace(0, 1, 20, False)\n",
    "    ]\n",
    "    return rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44d6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a79669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0:\n",
      "val_loss:\t5.45325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_log_loss:\t5.45618\n",
      "val_pre-ion_ma:\t0.00769\n",
      "val_recall_ma:\t0.00292\n",
      "val_f1_macro:\t0.00152\n",
      "val_accuracy:\t0.00288\n",
      "*\n",
      "\n",
      "epoch=1:\n",
      "train_loss:\t2.18812\n",
      "val_loss:\t1.27290\n",
      "val_log_loss:\t1.22177\n",
      "val_pre-ion_ma:\t0.29683\n",
      "val_recall_ma:\t0.20997\n",
      "val_f1_macro:\t0.21955\n",
      "val_accuracy:\t0.71486\n",
      "\n",
      "epoch=2:\n",
      "train_loss:\t1.00580\n",
      "val_loss:\t0.92283\n",
      "val_log_loss:\t0.88578\n",
      "val_pre-ion_ma:\t0.49309\n",
      "val_recall_ma:\t0.33366\n",
      "val_f1_macro:\t0.36803\n",
      "val_accuracy:\t0.77426\n",
      "\n",
      "epoch=3:\n",
      "train_loss:\t0.78887\n",
      "val_loss:\t0.80555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_log_loss:\t0.77419\n",
      "val_pre-ion_ma:\t0.56010\n",
      "val_recall_ma:\t0.39380\n",
      "val_f1_macro:\t0.43360\n",
      "val_accuracy:\t0.79152\n",
      "\n",
      "epoch=4:\n",
      "train_loss:\t0.68620\n",
      "val_loss:\t0.73103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_log_loss:\t0.70182\n",
      "val_pre-ion_ma:\t0.59643\n",
      "val_recall_ma:\t0.44098\n",
      "val_f1_macro:\t0.48108\n",
      "val_accuracy:\t0.81153\n",
      "\n",
      "epoch=5:\n",
      "train_loss:\t0.62035\n",
      "val_loss:\t0.68879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_log_loss:\t0.66101\n",
      "val_pre-ion_ma:\t0.60901\n",
      "val_recall_ma:\t0.46328\n",
      "val_f1_macro:\t0.50170\n",
      "val_accuracy:\t0.81903\n",
      "\n",
      "epoch=6:\n",
      "train_loss:\t0.57552\n",
      "val_loss:\t0.65731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_log_loss:\t0.63037\n",
      "val_pre-ion_ma:\t0.63120\n",
      "val_recall_ma:\t0.49638\n",
      "val_f1_macro:\t0.53440\n",
      "val_accuracy:\t0.83004\n",
      "\n",
      "epoch=7:\n",
      "train_loss:\t0.53428\n",
      "val_loss:\t0.63087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_log_loss:\t0.60722\n",
      "val_pre-ion_ma:\t0.64585\n",
      "val_recall_ma:\t0.51111\n",
      "val_f1_macro:\t0.55183\n",
      "val_accuracy:\t0.82904\n",
      "\n",
      "epoch=8:\n",
      "train_loss:\t0.50571\n",
      "val_loss:\t0.62434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/david_tyuman/.pyenv/versions/3.8.2/envs/mac_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_log_loss:\t0.59735\n",
      "val_pre-ion_ma:\t0.65856\n",
      "val_recall_ma:\t0.51474\n",
      "val_f1_macro:\t0.55500\n",
      "val_accuracy:\t0.83392\n",
      "\n",
      "epoch=9:\n",
      "train_loss: 0.4959\r"
     ]
    }
   ],
   "source": [
    "!rm -rf ./runs\n",
    "\n",
    "# default `log_dir` is \"runs\".\n",
    "writer = SummaryWriter('./runs')\n",
    "\n",
    "step = 0\n",
    "for epoch in range(epoch_nums):\n",
    "    print(f\"{epoch=}:\")\n",
    "\n",
    "    # Train model.\n",
    "    if epoch > 0:\n",
    "        net.train()\n",
    "        loss_history = []\n",
    "        for X, y in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = net(X)\n",
    "            loss_value = loss(y_pred, y)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            cur_train_loss = loss_value.cpu().data.item()\n",
    "            loss_history.append(cur_train_loss)\n",
    "            print(\"train_loss: %.4f\" % cur_train_loss, end='\\r')\n",
    "            \n",
    "            backbone_grad = np.hstack(\n",
    "                tuple(\n",
    "                    weights.grad.numpy().reshape(-1)\n",
    "                        for weights in filter(\n",
    "                            lambda w: w.grad is not None, net._backbone.parameters()\n",
    "                        )\n",
    "                )\n",
    "            ) \n",
    "            \n",
    "            head_grad = np.hstack(\n",
    "                tuple(\n",
    "                    weights.grad.numpy().reshape(-1)\n",
    "                        for weights in net._head.parameters()\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            writer.add_scalars(\n",
    "                \"Grad_norm\",\n",
    "                {\n",
    "                    \"backbone\": (backbone_grad ** 2).sum() ** 0.5,\n",
    "                    \"head\": (head_grad ** 2).sum() ** 0.5                    \n",
    "                },\n",
    "                step\n",
    "            )     \n",
    "            \n",
    "            step += 1\n",
    "\n",
    "        train_loss = np.mean(loss_history)\n",
    "        print(\"train_loss:\\t%.5f\" % train_loss)\n",
    "    else:\n",
    "        train_loss = -output_classes_num * np.log(1 / output_classes_num)\n",
    "\n",
    "    # Validate model.\n",
    "    net.eval()\n",
    "    loss_history = []\n",
    "    y_probs_history, y_true_history = [], []\n",
    "    embds_history = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_dataloader:\n",
    "            y_logits: torch.Tensor = net(X)\n",
    "            loss_value = loss(y_logits, y)\n",
    "            loss_history.append(loss_value.cpu().data.item())\n",
    "            \n",
    "            y_probs: np.ndarray = net.predict_proba(X)\n",
    "            y_true: np.ndarray = y.data.cpu().numpy().argmax(axis=1)\n",
    "            embds: np.ndarray = net.backbone(X).cpu().data.numpy()               \n",
    "            \n",
    "            y_probs_history.extend(y_probs.tolist())\n",
    "            y_true_history.extend(y_true.tolist())\n",
    "            embds_history.extend(embds.tolist())\n",
    "    val_loss = np.mean(loss_history)\n",
    "    print(\"val_loss:\\t%.5f\" % val_loss)            \n",
    "            \n",
    "    # Calculate calibration and save it it TB\n",
    "    probs_and_ratios = get_calibration(\n",
    "        np.array(y_probs_history).copy(),\n",
    "        np.array(y_true_history).copy()\n",
    "    )\n",
    "    \n",
    "    calibration_dict = {\n",
    "            \"%.3f\" % pair[0]: abs(pair[0] - pair[1]) for pair in probs_and_ratios\n",
    "    }\n",
    "    calibration_dict.update(\n",
    "        {\n",
    "            \"E\": np.mean(\n",
    "                [\n",
    "                    (pair[0] - pair[1]) ** 2 \n",
    "                        for pair in filter(\n",
    "                            lambda pair: not np.isnan(pair[1]),\n",
    "                            probs_and_ratios\n",
    "                        )\n",
    "                ]\n",
    "            ) ** 0.5\n",
    "        }    \n",
    "    )\n",
    "    writer.add_scalars('Calibration', calibration_dict, epoch)\n",
    "    \n",
    "    # Calculate metrics.\n",
    "    y_probs_history = np.array(y_probs_history)\n",
    "    y_pred_history = y_probs_history.argmax(axis=1)\n",
    "    metrics_values = {\n",
    "        metric[\"name\"]: metric[\"func\"](y_true_history, y_pred_history)\n",
    "            if metric[\"prediction_type\"] == \"categories\" else\n",
    "                metric[\"func\"](y_true_history, y_probs_history)\n",
    "            for metric in metrics\n",
    "    }\n",
    "    for name, metric_value in metrics_values.items():\n",
    "        print(f\"val_{name}:\\t%.5f\" % metric_value)\n",
    "    \n",
    "    # Save to TB images embeds.\n",
    "    writer.add_embedding(\n",
    "        np.array(embds_history[:EMBD_NUMBER_TO_SHOW]),\n",
    "        metadata=y_true_history[:EMBD_NUMBER_TO_SHOW],\n",
    "        global_step=epoch,\n",
    "        label_img=torch.concat(\n",
    "            [\n",
    "                val_dataset[i][0].unsqueeze(0)\n",
    "                    for i in range(len(val_dataset))\n",
    "            ]\n",
    "         )[:EMBD_NUMBER_TO_SHOW]\n",
    "    )\n",
    "\n",
    "    # Saving to TB.\n",
    "    writer.add_scalars(\n",
    "        'Loss',\n",
    "        {\n",
    "            \"train\": train_loss,\n",
    "            \"val\": val_loss\n",
    "        },\n",
    "        epoch\n",
    "    )\n",
    "\n",
    "    writer.add_scalars(\n",
    "        'Metric',\n",
    "        metrics_values,\n",
    "        epoch\n",
    "    )        \n",
    "    \n",
    "    # Save current best model.\n",
    "    if metrics_values[main_metric] < best_main_metric_value:\n",
    "        best_main_metric_value = metrics_values[main_metric]\n",
    "        torch.save(\n",
    "            {\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "            },\n",
    "            pathlib.Path(\"./road_signs_model.ckpt\")\n",
    "        )\n",
    "        print(\"*\")\n",
    "    print()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9447c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464215a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6884a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa72d6b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0015019525382997897,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 0,\n",
       " 4: 0.007872734554921398,\n",
       " 5: 0.005156703714829278,\n",
       " 6: 0,\n",
       " 7: 0.01757284469810754,\n",
       " 8: 0.0017022128767397618,\n",
       " 9: 0.0002878742365074597,\n",
       " 10: 0,\n",
       " 11: 0.0037423650745969763,\n",
       " 12: 0.0006383298287774106,\n",
       " 13: 0.0017397616901972564,\n",
       " 14: 0.0013392410133173124,\n",
       " 15: 0.001113948132572344,\n",
       " 16: 0,\n",
       " 17: 0,\n",
       " 18: 0.011039351156503454,\n",
       " 19: 0,\n",
       " 20: 0,\n",
       " 21: 0.007522278962651447,\n",
       " 22: 0.0006508460999299089,\n",
       " 23: 0,\n",
       " 24: 0,\n",
       " 25: 0.0011890457594873336,\n",
       " 26: 0.001164013217182337,\n",
       " 27: 0,\n",
       " 28: 0,\n",
       " 29: 0.0032041654150395515,\n",
       " 30: 0.002065184740162211,\n",
       " 31: 0,\n",
       " 32: 0,\n",
       " 33: 0.0005632322018624212,\n",
       " 34: 0,\n",
       " 35: 0,\n",
       " 36: 0,\n",
       " 37: 0.002690998297787123,\n",
       " 38: 0,\n",
       " 39: 0,\n",
       " 40: 0,\n",
       " 41: 0,\n",
       " 42: 0,\n",
       " 43: 0.004280564734154401,\n",
       " 44: 0,\n",
       " 45: 0.015745469109842796,\n",
       " 46: 0.0016896966055872634,\n",
       " 47: 0.0009887854210473615,\n",
       " 48: 0.011514969460298388,\n",
       " 49: 0,\n",
       " 50: 0.0002878742365074597,\n",
       " 51: 0,\n",
       " 52: 0,\n",
       " 53: 0.25037548813457494,\n",
       " 54: 0.00884900370481626,\n",
       " 55: 0.027748573145088617,\n",
       " 56: 0,\n",
       " 57: 0.11617602883748873,\n",
       " 58: 0.005319415239811756,\n",
       " 59: 0,\n",
       " 60: 0.013392410133173126,\n",
       " 61: 0,\n",
       " 62: 0,\n",
       " 63: 0.0012265945729448282,\n",
       " 64: 0,\n",
       " 65: 0,\n",
       " 66: 0.02092720536697707,\n",
       " 67: 0,\n",
       " 68: 0.00017522779613497546,\n",
       " 69: 0.0004505857614899369,\n",
       " 70: 0.004105336938019425,\n",
       " 71: 0.004530890157204366,\n",
       " 72: 0.001364273555622309,\n",
       " 73: 0,\n",
       " 74: 0,\n",
       " 75: 0.008310804045258836,\n",
       " 76: 0.0002878742365074597,\n",
       " 77: 0,\n",
       " 78: 0.00030039050765995795,\n",
       " 79: 0.009587463702813657,\n",
       " 80: 0,\n",
       " 81: 0,\n",
       " 82: 0,\n",
       " 83: 8.761389806748773e-05,\n",
       " 84: 0.02350555722439171,\n",
       " 85: 0,\n",
       " 86: 0,\n",
       " 87: 0.0031040352458195654,\n",
       " 88: 0.002415640332432162,\n",
       " 89: 0.0018023430459597476,\n",
       " 90: 0.0002628416942024632,\n",
       " 91: 0,\n",
       " 92: 0.0022028637228396915,\n",
       " 93: 0,\n",
       " 94: 0.009149394212476219,\n",
       " 95: 0.0005381996595574247,\n",
       " 96: 0.00032542304996495446,\n",
       " 97: 0.009549914889356163,\n",
       " 98: 0.006533493541604085,\n",
       " 99: 0.0002878742365074597,\n",
       " 100: 0,\n",
       " 101: 0.0005381996595574247,\n",
       " 102: 0.0008385901672173826,\n",
       " 103: 0,\n",
       " 104: 0,\n",
       " 105: 0,\n",
       " 106: 0,\n",
       " 107: 0,\n",
       " 108: 0,\n",
       " 109: 0.0022153799939921897,\n",
       " 110: 0,\n",
       " 111: 0.009024231500951236,\n",
       " 112: 0.004555922699509362,\n",
       " 113: 0,\n",
       " 114: 0,\n",
       " 115: 0,\n",
       " 116: 0,\n",
       " 117: 0.0028537098227696006,\n",
       " 118: 0,\n",
       " 119: 0,\n",
       " 120: 0.0063457494743166115,\n",
       " 121: 0,\n",
       " 122: 0.005156703714829278,\n",
       " 123: 0.0007134274556924001,\n",
       " 124: 0,\n",
       " 125: 0,\n",
       " 126: 0,\n",
       " 127: 0,\n",
       " 128: 0.0013517572844698109,\n",
       " 129: 0,\n",
       " 130: 0,\n",
       " 131: 0.003329328126564534,\n",
       " 132: 0,\n",
       " 133: 0,\n",
       " 134: 0.0003504555922699509,\n",
       " 135: 0,\n",
       " 136: 0.0009011715229798738,\n",
       " 137: 0.00884900370481626,\n",
       " 138: 8.761389806748773e-05,\n",
       " 139: 0.0014018223690798037,\n",
       " 140: 0.0005882647441674176,\n",
       " 141: 0,\n",
       " 142: 0.011615099629518373,\n",
       " 143: 0,\n",
       " 144: 0.0009387203364373686,\n",
       " 145: 0,\n",
       " 146: 0,\n",
       " 147: 0.009074296585561229,\n",
       " 148: 0.00020026033843997197,\n",
       " 149: 0.00046310203264243515,\n",
       " 150: 0.0035546210073095024,\n",
       " 151: 1.2516271152498248e-05,\n",
       " 152: 0,\n",
       " 153: 0,\n",
       " 154: 0,\n",
       " 155: 0,\n",
       " 156: 0.019162411134474817,\n",
       " 157: 0,\n",
       " 158: 0.03550866125963753,\n",
       " 159: 0,\n",
       " 160: 0.011978071492940823,\n",
       " 161: 0,\n",
       " 162: 0,\n",
       " 163: 0.0004505857614899369,\n",
       " 164: 0,\n",
       " 165: 0,\n",
       " 166: 0,\n",
       " 167: 0.001414338640232302,\n",
       " 168: 0,\n",
       " 169: 0.005006508460999299,\n",
       " 170: 0,\n",
       " 171: 0.0001877440672874737,\n",
       " 172: 0.0013767898267748073,\n",
       " 173: 0.002678482026634625,\n",
       " 174: 0.01177781115450085,\n",
       " 175: 0.0017272454190447582,\n",
       " 176: 0,\n",
       " 177: 0,\n",
       " 178: 0,\n",
       " 179: 0,\n",
       " 180: 0.0012265945729448282,\n",
       " 181: 0.0029288074496845898,\n",
       " 182: 0,\n",
       " 183: 0,\n",
       " 184: 0.0003504555922699509,\n",
       " 185: 0.0033793932111745267,\n",
       " 186: 0,\n",
       " 187: 0,\n",
       " 188: 0.04106588565134675,\n",
       " 189: 0.001564533894062281,\n",
       " 190: 0.00012516271152498247,\n",
       " 191: 0,\n",
       " 192: 0,\n",
       " 193: 0,\n",
       " 194: 0.0010138179633523581,\n",
       " 195: 0.052618403925102634,\n",
       " 196: 0.0010513667768098527,\n",
       " 197: 0.0008385901672173826,\n",
       " 198: 0.010388505056573545,\n",
       " 199: 0.0649719635526184,\n",
       " 200: 0.009650045058576149,\n",
       " 201: 0.002440672874737158,\n",
       " 202: 0,\n",
       " 203: 0,\n",
       " 204: 0,\n",
       " 205: 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ImageClassifyDataset(\n",
    "    mode=\"train\",\n",
    "    val_type=val_type,\n",
    "    train_fraction=1.0,\n",
    "    root_folder=pathlib.Path('/home/david_tyuman/my_github/cv_fall_2022/lesson_8_detection_metric/cropped-train'),\n",
    "    classes_num=output_classes_num,\n",
    "    new_size=new_size,\n",
    "    transforms=None\n",
    ")\n",
    "\n",
    "correct_priors = {ds._class_name_to_id[k]: len(v) / len(ds) for k, v in ds._items_groups.items()}\n",
    "for i in range(206):\n",
    "    if i in correct_priors:\n",
    "        pass\n",
    "    else:\n",
    "        correct_priors[i] = 0\n",
    "correct_priors = dict(sorted(correct_priors.items(), key=lambda x: x[0]))\n",
    "correct_priors\n",
    "# p(y|x) = p(y) * p(x|y) / p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e7a7b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss:\t1.36652\n",
      "val_recall_ma:\t0.61171\n",
      "val_f1_macro:\t0.64944\n",
      "val_accuracy:\t0.86556\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "loss_history = []\n",
    "y_probs_history, y_true_history = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in val_dataloader:\n",
    "        y_logits: torch.Tensor = net(X)\n",
    "        loss_value = loss(y_logits, y)\n",
    "        loss_history.append(loss_value.cpu().data.item())\n",
    "\n",
    "        y_probs: np.ndarray = net.predict_proba(X).cpu().data.numpy()\n",
    "        y_true: np.ndarray = y.data.cpu().numpy().argmax(axis=1)\n",
    "        embds: np.ndarray = net.backbone(X).cpu().data.numpy()\n",
    "            \n",
    "        for class_id, p in list(correct_priors.items())[:-1]:\n",
    "            y_probs[:, class_id] = y_probs[:, class_id] * (1/105) * p\n",
    "        y_probs /= y_probs.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "        y_probs_history.extend(y_probs.tolist())\n",
    "        y_true_history.extend(y_true.tolist())\n",
    "        \n",
    "val_loss = np.mean(loss_history)\n",
    "print(\"val_loss:\\t%.5f\" % val_loss)\n",
    "\n",
    "y_pred_history = np.array(y_probs_history).argmax(axis=1)\n",
    "metrics_values = {\n",
    "    metric[\"name\"]: metric[\"func\"](y_true_history, y_pred_history)\n",
    "        for metric in metrics[1:]\n",
    "}\n",
    "for name, metric_value in metrics_values.items():\n",
    "    print(f\"val_{name}:\\t%.5f\" % metric_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cdba9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "                \"0\": 0.0015019525382997897,\n",
      "                \"1\": 0,\n",
      "                \"2\": 0,\n",
      "                \"3\": 0,\n",
      "                \"4\": 0.007872734554921398,\n",
      "                \"5\": 0.005156703714829278,\n",
      "                \"6\": 0,\n",
      "                \"7\": 0.01757284469810754,\n",
      "                \"8\": 0.0017022128767397618,\n",
      "                \"9\": 0.0002878742365074597,\n",
      "                \"10\": 0,\n",
      "                \"11\": 0.0037423650745969763,\n",
      "                \"12\": 0.0006383298287774106,\n",
      "                \"13\": 0.0017397616901972564,\n",
      "                \"14\": 0.0013392410133173124,\n",
      "                \"15\": 0.001113948132572344,\n",
      "                \"16\": 0,\n",
      "                \"17\": 0,\n",
      "                \"18\": 0.011039351156503454,\n",
      "                \"19\": 0,\n",
      "                \"20\": 0,\n",
      "                \"21\": 0.007522278962651447,\n",
      "                \"22\": 0.0006508460999299089,\n",
      "                \"23\": 0,\n",
      "                \"24\": 0,\n",
      "                \"25\": 0.0011890457594873336,\n",
      "                \"26\": 0.001164013217182337,\n",
      "                \"27\": 0,\n",
      "                \"28\": 0,\n",
      "                \"29\": 0.0032041654150395515,\n",
      "                \"30\": 0.002065184740162211,\n",
      "                \"31\": 0,\n",
      "                \"32\": 0,\n",
      "                \"33\": 0.0005632322018624212,\n",
      "                \"34\": 0,\n",
      "                \"35\": 0,\n",
      "                \"36\": 0,\n",
      "                \"37\": 0.002690998297787123,\n",
      "                \"38\": 0,\n",
      "                \"39\": 0,\n",
      "                \"40\": 0,\n",
      "                \"41\": 0,\n",
      "                \"42\": 0,\n",
      "                \"43\": 0.004280564734154401,\n",
      "                \"44\": 0,\n",
      "                \"45\": 0.015745469109842796,\n",
      "                \"46\": 0.0016896966055872634,\n",
      "                \"47\": 0.0009887854210473615,\n",
      "                \"48\": 0.011514969460298388,\n",
      "                \"49\": 0,\n",
      "                \"50\": 0.0002878742365074597,\n",
      "                \"51\": 0,\n",
      "                \"52\": 0,\n",
      "                \"53\": 0.25037548813457494,\n",
      "                \"54\": 0.00884900370481626,\n",
      "                \"55\": 0.027748573145088617,\n",
      "                \"56\": 0,\n",
      "                \"57\": 0.11617602883748873,\n",
      "                \"58\": 0.005319415239811756,\n",
      "                \"59\": 0,\n",
      "                \"60\": 0.013392410133173126,\n",
      "                \"61\": 0,\n",
      "                \"62\": 0,\n",
      "                \"63\": 0.0012265945729448282,\n",
      "                \"64\": 0,\n",
      "                \"65\": 0,\n",
      "                \"66\": 0.02092720536697707,\n",
      "                \"67\": 0,\n",
      "                \"68\": 0.00017522779613497546,\n",
      "                \"69\": 0.0004505857614899369,\n",
      "                \"70\": 0.004105336938019425,\n",
      "                \"71\": 0.004530890157204366,\n",
      "                \"72\": 0.001364273555622309,\n",
      "                \"73\": 0,\n",
      "                \"74\": 0,\n",
      "                \"75\": 0.008310804045258836,\n",
      "                \"76\": 0.0002878742365074597,\n",
      "                \"77\": 0,\n",
      "                \"78\": 0.00030039050765995795,\n",
      "                \"79\": 0.009587463702813657,\n",
      "                \"80\": 0,\n",
      "                \"81\": 0,\n",
      "                \"82\": 0,\n",
      "                \"83\": 8.761389806748773e-05,\n",
      "                \"84\": 0.02350555722439171,\n",
      "                \"85\": 0,\n",
      "                \"86\": 0,\n",
      "                \"87\": 0.0031040352458195654,\n",
      "                \"88\": 0.002415640332432162,\n",
      "                \"89\": 0.0018023430459597476,\n",
      "                \"90\": 0.0002628416942024632,\n",
      "                \"91\": 0,\n",
      "                \"92\": 0.0022028637228396915,\n",
      "                \"93\": 0,\n",
      "                \"94\": 0.009149394212476219,\n",
      "                \"95\": 0.0005381996595574247,\n",
      "                \"96\": 0.00032542304996495446,\n",
      "                \"97\": 0.009549914889356163,\n",
      "                \"98\": 0.006533493541604085,\n",
      "                \"99\": 0.0002878742365074597,\n",
      "                \"100\": 0,\n",
      "                \"101\": 0.0005381996595574247,\n",
      "                \"102\": 0.0008385901672173826,\n",
      "                \"103\": 0,\n",
      "                \"104\": 0,\n",
      "                \"105\": 0,\n",
      "                \"106\": 0,\n",
      "                \"107\": 0,\n",
      "                \"108\": 0,\n",
      "                \"109\": 0.0022153799939921897,\n",
      "                \"110\": 0,\n",
      "                \"111\": 0.009024231500951236,\n",
      "                \"112\": 0.004555922699509362,\n",
      "                \"113\": 0,\n",
      "                \"114\": 0,\n",
      "                \"115\": 0,\n",
      "                \"116\": 0,\n",
      "                \"117\": 0.0028537098227696006,\n",
      "                \"118\": 0,\n",
      "                \"119\": 0,\n",
      "                \"120\": 0.0063457494743166115,\n",
      "                \"121\": 0,\n",
      "                \"122\": 0.005156703714829278,\n",
      "                \"123\": 0.0007134274556924001,\n",
      "                \"124\": 0,\n",
      "                \"125\": 0,\n",
      "                \"126\": 0,\n",
      "                \"127\": 0,\n",
      "                \"128\": 0.0013517572844698109,\n",
      "                \"129\": 0,\n",
      "                \"130\": 0,\n",
      "                \"131\": 0.003329328126564534,\n",
      "                \"132\": 0,\n",
      "                \"133\": 0,\n",
      "                \"134\": 0.0003504555922699509,\n",
      "                \"135\": 0,\n",
      "                \"136\": 0.0009011715229798738,\n",
      "                \"137\": 0.00884900370481626,\n",
      "                \"138\": 8.761389806748773e-05,\n",
      "                \"139\": 0.0014018223690798037,\n",
      "                \"140\": 0.0005882647441674176,\n",
      "                \"141\": 0,\n",
      "                \"142\": 0.011615099629518373,\n",
      "                \"143\": 0,\n",
      "                \"144\": 0.0009387203364373686,\n",
      "                \"145\": 0,\n",
      "                \"146\": 0,\n",
      "                \"147\": 0.009074296585561229,\n",
      "                \"148\": 0.00020026033843997197,\n",
      "                \"149\": 0.00046310203264243515,\n",
      "                \"150\": 0.0035546210073095024,\n",
      "                \"151\": 1.2516271152498248e-05,\n",
      "                \"152\": 0,\n",
      "                \"153\": 0,\n",
      "                \"154\": 0,\n",
      "                \"155\": 0,\n",
      "                \"156\": 0.019162411134474817,\n",
      "                \"157\": 0,\n",
      "                \"158\": 0.03550866125963753,\n",
      "                \"159\": 0,\n",
      "                \"160\": 0.011978071492940823,\n",
      "                \"161\": 0,\n",
      "                \"162\": 0,\n",
      "                \"163\": 0.0004505857614899369,\n",
      "                \"164\": 0,\n",
      "                \"165\": 0,\n",
      "                \"166\": 0,\n",
      "                \"167\": 0.001414338640232302,\n",
      "                \"168\": 0,\n",
      "                \"169\": 0.005006508460999299,\n",
      "                \"170\": 0,\n",
      "                \"171\": 0.0001877440672874737,\n",
      "                \"172\": 0.0013767898267748073,\n",
      "                \"173\": 0.002678482026634625,\n",
      "                \"174\": 0.01177781115450085,\n",
      "                \"175\": 0.0017272454190447582,\n",
      "                \"176\": 0,\n",
      "                \"177\": 0,\n",
      "                \"178\": 0,\n",
      "                \"179\": 0,\n",
      "                \"180\": 0.0012265945729448282,\n",
      "                \"181\": 0.0029288074496845898,\n",
      "                \"182\": 0,\n",
      "                \"183\": 0,\n",
      "                \"184\": 0.0003504555922699509,\n",
      "                \"185\": 0.0033793932111745267,\n",
      "                \"186\": 0,\n",
      "                \"187\": 0,\n",
      "                \"188\": 0.04106588565134675,\n",
      "                \"189\": 0.001564533894062281,\n",
      "                \"190\": 0.00012516271152498247,\n",
      "                \"191\": 0,\n",
      "                \"192\": 0,\n",
      "                \"193\": 0,\n",
      "                \"194\": 0.0010138179633523581,\n",
      "                \"195\": 0.052618403925102634,\n",
      "                \"196\": 0.0010513667768098527,\n",
      "                \"197\": 0.0008385901672173826,\n",
      "                \"198\": 0.010388505056573545,\n",
      "                \"199\": 0.0649719635526184,\n",
      "                \"200\": 0.009650045058576149,\n",
      "                \"201\": 0.002440672874737158,\n",
      "                \"202\": 0,\n",
      "                \"203\": 0,\n",
      "                \"204\": 0,\n",
      "                \"205\": 0,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"{\")\n",
    "for k, v in correct_priors.items():\n",
    "    print(f'                \"{k}\": {v},')\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbfbdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f4bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74805063",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ClassifyNetwork(\n",
    "    base_net=getattr(models, network_params[\"base_net\"][\"type\"])(\n",
    "        **network_params[\"base_net\"][\"params\"]\n",
    "    ),\n",
    "    internal_features=network_params[\"internal_features\"],\n",
    "    output_classes_num=output_classes_num\n",
    ")\n",
    "optimizer = getattr(torch.optim, optimizer_params[\"optimizer_type\"])(\n",
    "    net.parameters(),\n",
    "    **optimizer_params[\"params\"]\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"./road_signs_model.ckpt\")\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bc05c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_history = []\n",
    "y_history = []\n",
    "for X, y in val_dataloader:\n",
    "    y_probs = net.predict_proba(X).cpu().data.numpy().tolist()\n",
    "    y_probs_history.extend(y_probs)\n",
    "    \n",
    "    y = y.argmax(dim=1).numpy().tolist()\n",
    "    y_history.extend(y)\n",
    "    \n",
    "y_probs = np.array(y_probs_history)\n",
    "y = np.array(y_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c772d8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04203754064863384"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_probs.argmax(axis=1)\n",
    "\n",
    "y_max_probs = y_probs[range(y.shape[0]), y_pred]\n",
    "sort_args = np.argsort(y_max_probs)\n",
    "\n",
    "y_max_probs = y_max_probs[sort_args]\n",
    "results = y[sort_args] == y_pred[sort_args]\n",
    "\n",
    "rez = []\n",
    "for i in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    mask = (i < y_max_probs) & (y_max_probs < (i + 0.1))\n",
    "    bin_ = y_max_probs[mask]\n",
    "    ratio = np.mean(results[mask])\n",
    "    if np.any(np.isnan(ratio)):\n",
    "        continue\n",
    "    rez.append((i + 0.05, np.mean(results[mask])))\n",
    "\n",
    "E = 0\n",
    "for pair in rez:\n",
    "    E += (pair[0] - pair[1]) ** 2\n",
    "E = (E / len(rez)) ** 0.5\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0f8131b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.15000000000000002, 0.17857142857142858),\n",
       " (0.25, 0.3047619047619048),\n",
       " (0.35, 0.35398230088495575),\n",
       " (0.45, 0.43288590604026844),\n",
       " (0.55, 0.5),\n",
       " (0.65, 0.5837988826815642),\n",
       " (0.75, 0.7211538461538461),\n",
       " (0.8500000000000001, 0.7928692699490663),\n",
       " (0.9500000000000001, 0.9783167952958471)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4fee55c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05, nan),\n",
       " (0.15000000000000002, 0.0),\n",
       " (0.25, 0.42857142857142855),\n",
       " (0.35, 0.5925925925925926),\n",
       " (0.45, 0.46511627906976744),\n",
       " (0.55, 0.6129032258064516),\n",
       " (0.65, 0.6274509803921569),\n",
       " (0.75, 0.7962962962962963),\n",
       " (0.8500000000000001, 0.8289473684210527),\n",
       " (0.9500000000000001, 0.9910179640718563)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4900406",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "either both or neither of x and y should be given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4607/4118953988.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_max_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0my_max_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_max_probs\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: either both or neither of x and y should be given"
     ]
    }
   ],
   "source": [
    "i = 0.1\n",
    "np.where(y_max_probs, (i < y_max_probs) & (y_max_probs < (i + 0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f237f3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.5483298e-05, 1.4772819e-14, 1.4273133e-13, ..., 2.6288084e-13,\n",
       "        3.5562333e-14, 8.1335011e-14],\n",
       "       [2.6610178e-06, 1.2739876e-15, 1.4398149e-14, ..., 3.6002766e-14,\n",
       "        2.7983781e-15, 1.2244070e-14],\n",
       "       [5.6783983e-10, 2.3162514e-14, 6.5040597e-14, ..., 5.4292894e-14,\n",
       "        1.4634239e-14, 9.0630703e-14],\n",
       "       ...,\n",
       "       [8.6203697e-11, 2.8679354e-17, 1.0564560e-17, ..., 8.2759480e-17,\n",
       "        3.0280458e-17, 4.2828560e-17],\n",
       "       [9.2028388e-14, 1.3221229e-29, 1.1885842e-29, ..., 1.1067550e-28,\n",
       "        4.5476420e-30, 5.3528334e-30],\n",
       "       [7.8783377e-12, 5.2823892e-16, 7.0931984e-16, ..., 2.7075910e-15,\n",
       "        1.8008454e-16, 1.2500440e-15]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e122e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35974a39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.548329788027331e-05,\n",
       " 2.661017788341269e-06,\n",
       " 5.678398307118471e-10,\n",
       " 9.541906820231816e-07,\n",
       " 4.5149221250539995e-08,\n",
       " 4.739329154818117e-12,\n",
       " 0.009538363665342331,\n",
       " 3.8132889130793046e-06,\n",
       " 1.1474638085928746e-05,\n",
       " 1.3246311510746575e-16,\n",
       " 3.826086867775302e-06,\n",
       " 9.288743385571507e-12,\n",
       " 4.790371432861207e-10,\n",
       " 2.2715434812000182e-14,\n",
       " 1.307827375285342e-07,\n",
       " 2.544249753100303e-07,\n",
       " 1.9509691639996163e-09,\n",
       " 0.01645510643720627,\n",
       " 0.0001329982915194705,\n",
       " 1.4613917714845215e-11,\n",
       " 4.2789380437328883e-14,\n",
       " 1.5838068547583449e-18,\n",
       " 0.025467244908213615,\n",
       " 3.0824320873534816e-09,\n",
       " 2.0137853606883027e-09,\n",
       " 1.886359677882865e-05,\n",
       " 9.988932106352877e-06,\n",
       " 5.618929321826727e-09,\n",
       " 3.004188965736315e-13,\n",
       " 6.25981328994385e-07,\n",
       " 9.950562974852052e-19,\n",
       " 3.0134853659546934e-05,\n",
       " 1.8239314572565668e-11,\n",
       " 1.4503267493637395e-06,\n",
       " 6.92862032069932e-17,\n",
       " 1.5633878913678956e-10,\n",
       " 8.877774554787187e-16,\n",
       " 5.433479865037463e-14,\n",
       " 1.7962509951674477e-11,\n",
       " 1.7175477706743436e-09,\n",
       " 7.456380348228042e-13,\n",
       " 3.583358821288904e-18,\n",
       " 8.395378614522997e-09,\n",
       " 0.0002530756755732,\n",
       " 8.47866268855721e-16,\n",
       " 2.5559589760312936e-15,\n",
       " 3.289691903773928e-06,\n",
       " 1.0119613480519263e-11,\n",
       " 4.1377660409125383e-07,\n",
       " 4.3709331265517903e-08,\n",
       " 2.8832105272158515e-06,\n",
       " 1.024977214214573e-09,\n",
       " 0.0038696937263011932,\n",
       " 2.4286178401666803e-08,\n",
       " 1.505004011395823e-15,\n",
       " 2.3941698623630714e-10,\n",
       " 2.4034424624119755e-12,\n",
       " 1.7917980130732758e-06,\n",
       " 0.00039678107714280486,\n",
       " 4.6422832156167715e-07,\n",
       " 8.145993213304337e-09,\n",
       " 3.417224728012591e-13,\n",
       " 3.104596908087842e-05,\n",
       " 5.638153499631926e-09,\n",
       " 9.97323317680765e-13,\n",
       " 2.010230648608058e-09,\n",
       " 1.1764604589993566e-13,\n",
       " 1.1291165918914103e-11,\n",
       " 3.1362173968929596e-10,\n",
       " 1.5901129302164918e-07,\n",
       " 2.244647732699614e-17,\n",
       " 6.611371645703912e-05,\n",
       " 8.099722492715955e-08,\n",
       " 0.0004935974138788879,\n",
       " 3.8275469705695286e-05,\n",
       " 5.641868119710125e-05,\n",
       " 1.3482130993211494e-12,\n",
       " 0.00023423867241945118,\n",
       " 1.5068960124153818e-07,\n",
       " 0.004137244541198015,\n",
       " 2.464073816099699e-07,\n",
       " 3.693201522381173e-09,\n",
       " 6.829010967823734e-11,\n",
       " 1.099366090784315e-05,\n",
       " 4.997122232452966e-06,\n",
       " 4.97562798254525e-12,\n",
       " 2.6893123145077524e-11,\n",
       " 6.298993326936397e-09,\n",
       " 4.803738651434561e-14,\n",
       " 2.565458423475775e-08,\n",
       " 0.0003542302583809942,\n",
       " 2.0288069455757368e-13,\n",
       " 3.843057699907925e-21,\n",
       " 6.3079823482692365e-12,\n",
       " 1.9745975965435036e-09,\n",
       " 1.6288310007439577e-06,\n",
       " 1.3021365929954953e-10,\n",
       " 3.0358308640392184e-13,\n",
       " 5.903761366495702e-14,\n",
       " 1.2290691131511267e-07,\n",
       " 3.270939963329056e-09,\n",
       " 4.158686550681523e-08,\n",
       " 1.9439036491597506e-10,\n",
       " 6.618096293209419e-09,\n",
       " 0.0003365041920915246,\n",
       " 4.49457981943624e-09,\n",
       " 2.5620185972741183e-09,\n",
       " 0.0004661979037337005,\n",
       " 3.5798632946892894e-09,\n",
       " 6.6317491693209784e-15,\n",
       " 2.758911289412347e-21,\n",
       " 3.429273087718343e-09,\n",
       " 1.2176393511253991e-06,\n",
       " 0.00028689761529676616,\n",
       " 2.6613660164542807e-09,\n",
       " 1.9194568157132608e-09,\n",
       " 2.0900933761502927e-11,\n",
       " 1.1325469131406862e-05,\n",
       " 0.002522300463169813,\n",
       " 8.992383868644538e-07,\n",
       " 8.408147955663026e-09,\n",
       " 0.0005156967090442777,\n",
       " 1.48437349164404e-16,\n",
       " 0.0003084636991843581,\n",
       " 6.134953228448899e-16,\n",
       " 1.1904876373591833e-06,\n",
       " 1.0094387107528746e-05,\n",
       " 3.903232459467887e-10,\n",
       " 4.0490215347244174e-11,\n",
       " 3.9960834641306064e-10,\n",
       " 3.813179980105552e-11,\n",
       " 9.868615646890788e-11,\n",
       " 1.9352834890185022e-09,\n",
       " 1.966769377759192e-05,\n",
       " 1.9464808237446007e-11,\n",
       " 8.365443076750398e-14,\n",
       " 1.1089366758199048e-08,\n",
       " 1.0939952943544995e-08,\n",
       " 1.171627900475869e-06,\n",
       " 1.0483473289468748e-07,\n",
       " 1.050548426029252e-09,\n",
       " 2.6633415473042987e-07,\n",
       " 0.0002799126668833196,\n",
       " 2.790940872507419e-12,\n",
       " 2.5133635949380062e-14,\n",
       " 5.540950337445949e-11,\n",
       " 1.1678616407273523e-11,\n",
       " 0.00011690639075823128,\n",
       " 1.343775923867696e-10,\n",
       " 3.322075372125255e-06,\n",
       " 2.602756898895109e-10,\n",
       " 2.728519188366363e-09,\n",
       " 5.5478253102592134e-09,\n",
       " 5.282730919375922e-10,\n",
       " 1.2183940447806248e-14,\n",
       " 2.134951590515577e-11,\n",
       " 6.2324847505124126e-09,\n",
       " 5.206297545856664e-11,\n",
       " 2.151761581414835e-11,\n",
       " 8.829523068243361e-08,\n",
       " 1.755634571054543e-08,\n",
       " 1.6772534749964763e-10,\n",
       " 3.234617573788512e-10,\n",
       " 2.8966924414675077e-09,\n",
       " 5.0756020913977906e-11,\n",
       " 1.710014601030707e-07,\n",
       " 2.3070970200933516e-06,\n",
       " 1.1503253904976418e-10,\n",
       " 2.992897041309561e-10,\n",
       " 7.353569047630938e-15,\n",
       " 0.00023858733766246587,\n",
       " 1.830735189943674e-16,\n",
       " 2.7479918571771123e-06,\n",
       " 3.3754502055671765e-06,\n",
       " 2.737243764983077e-10,\n",
       " 3.106291615040391e-07,\n",
       " 2.399888066051403e-10,\n",
       " 6.673707364512893e-09,\n",
       " 1.5627127369910454e-10,\n",
       " 2.8352944991816287e-11,\n",
       " 1.4413419346936962e-09,\n",
       " 7.418684253934771e-05,\n",
       " 8.501456760789949e-10,\n",
       " 3.142847260232362e-17,\n",
       " 1.5075620751758834e-08,\n",
       " 8.032788173295557e-06,\n",
       " 1.6727606180211296e-06,\n",
       " 8.551088370722937e-08,\n",
       " 5.093302082176399e-13,\n",
       " 1.5239341166761733e-07,\n",
       " 2.881639649121581e-10,\n",
       " 2.06933165047829e-10,\n",
       " 3.058558295521152e-09,\n",
       " 2.8460674002417363e-05,\n",
       " 2.0205263243783245e-12,\n",
       " 2.2204302285722122e-10,\n",
       " 5.503020608643716e-11,\n",
       " 0.00016931176651269197,\n",
       " 8.38737824852831e-13,\n",
       " 1.8462841525805976e-14,\n",
       " 1.0927362836810062e-06,\n",
       " 6.560766223628889e-07,\n",
       " 1.3450406344261978e-09,\n",
       " 1.638404967252427e-10,\n",
       " 3.010286775406712e-08,\n",
       " 8.499361804636951e-12,\n",
       " 1.5773982868592246e-13,\n",
       " 1.3936751058762908e-12,\n",
       " 2.4079347404892815e-09,\n",
       " 3.5820899029204156e-06,\n",
       " 2.8128282792749815e-05,\n",
       " 3.344038123032078e-05,\n",
       " 2.3581215105594744e-12,\n",
       " 8.449593025261493e-09,\n",
       " 1.5658575547305986e-09,\n",
       " 3.9749303937242075e-07,\n",
       " 4.7396874833793845e-06,\n",
       " 2.7478726849494706e-08,\n",
       " 6.430563530557265e-07,\n",
       " 5.5149163014078795e-11,\n",
       " 0.04728185012936592,\n",
       " 5.815292691835339e-10,\n",
       " 2.8961089526546857e-08,\n",
       " 1.1799081711671988e-09,\n",
       " 1.3500814735847746e-15,\n",
       " 7.853868311258339e-08,\n",
       " 1.1045656068671503e-14,\n",
       " 3.4049016051085346e-08,\n",
       " 1.5498952052439563e-05,\n",
       " 1.4344595733462029e-08,\n",
       " 3.972949746966492e-11,\n",
       " 0.00015185591473709792,\n",
       " 0.0003769433533307165,\n",
       " 3.9921204120219045e-08,\n",
       " 7.994330530891602e-08,\n",
       " 7.624149250297363e-13,\n",
       " 6.871375699997894e-18,\n",
       " 1.222271295745034e-15,\n",
       " 1.8659263787412783e-06,\n",
       " 3.710446949689583e-10,\n",
       " 3.00377145379116e-08,\n",
       " 3.429029927842428e-14,\n",
       " 0.006776909809559584,\n",
       " 7.39429155266633e-25,\n",
       " 0.00036129553336650133,\n",
       " 4.7928958579745995e-09,\n",
       " 1.880828494904563e-05,\n",
       " 6.635749283390169e-09,\n",
       " 1.0777202107221284e-20,\n",
       " 3.5603184844745783e-09,\n",
       " 0.000720470561645925,\n",
       " 0.00017706953804008663,\n",
       " 6.429435650545656e-09,\n",
       " 8.35608859883763e-10,\n",
       " 1.8712853803396629e-13,\n",
       " 7.63982868079438e-08,\n",
       " 2.5420865767955547e-07,\n",
       " 2.3188817532826533e-10,\n",
       " 4.2907672650471795e-06,\n",
       " 7.305692162340449e-11,\n",
       " 9.034025083565211e-08,\n",
       " 3.223246517095768e-19,\n",
       " 9.066909115063027e-06,\n",
       " 4.196539293843671e-07,\n",
       " 2.301399630762202e-13,\n",
       " 1.2747971140925074e-06,\n",
       " 5.653405521499621e-10,\n",
       " 1.1292672041918195e-07,\n",
       " 1.9339745936978146e-14,\n",
       " 2.81299162452342e-05,\n",
       " 2.764380369058017e-08,\n",
       " 3.804824836271814e-13,\n",
       " 8.288658648325509e-09,\n",
       " 0.00031335276435129344,\n",
       " 2.8884850067356638e-09,\n",
       " 0.000387643463909626,\n",
       " 1.2831526639833779e-11,\n",
       " 4.78644413600543e-13,\n",
       " 1.8222961795143558e-14,\n",
       " 9.237057838618057e-07,\n",
       " 0.0001478715566918254,\n",
       " 2.128634406517449e-07,\n",
       " 4.022678898156235e-15,\n",
       " 0.00032397889299318194,\n",
       " 2.3850418168214205e-11,\n",
       " 5.835102712126172e-08,\n",
       " 1.0142935796819685e-10,\n",
       " 1.8282134988112375e-06,\n",
       " 2.0709095549520384e-10,\n",
       " 2.19783128599816e-14,\n",
       " 1.150148546003038e-05,\n",
       " 3.9638861637492084e-11,\n",
       " 1.180676514672338e-13,\n",
       " 2.1922712534205857e-09,\n",
       " 5.069569510851579e-07,\n",
       " 1.0203386409557424e-05,\n",
       " 1.6611370612373833e-10,\n",
       " 0.000462759897345677,\n",
       " 0.001896688248962164,\n",
       " 4.999231251190395e-08,\n",
       " 1.1069771517213667e-06,\n",
       " 2.930575053461393e-12,\n",
       " 1.3214279533713125e-05,\n",
       " 6.3111295703355275e-12,\n",
       " 1.2876333244093985e-07,\n",
       " 3.9262622558537685e-13,\n",
       " 3.088458822020357e-09,\n",
       " 9.09844144469929e-11,\n",
       " 6.454311911319177e-12,\n",
       " 8.212370128553304e-13,\n",
       " 1.9222682595535813e-14,\n",
       " 2.3243596558586432e-07,\n",
       " 1.1838612103232484e-15,\n",
       " 6.104065874978915e-08,\n",
       " 1.937349225045182e-06,\n",
       " 0.0019142684759572148,\n",
       " 1.0644149597283104e-06,\n",
       " 4.533661012828816e-06,\n",
       " 1.5832688493588876e-09,\n",
       " 5.558196676247462e-07,\n",
       " 3.325642683194019e-05,\n",
       " 8.570548288844293e-07,\n",
       " 3.427786765541896e-08,\n",
       " 5.713036637931712e-18,\n",
       " 9.537696143979701e-08,\n",
       " 7.321324102527171e-10,\n",
       " 1.3532475140465294e-10,\n",
       " 5.543381725869878e-12,\n",
       " 6.928122076033105e-08,\n",
       " 6.407755938631009e-17,\n",
       " 2.0512441096798284e-06,\n",
       " 1.2530326110038459e-08,\n",
       " 1.1512495817767032e-11,\n",
       " 1.77706329651528e-08,\n",
       " 3.1309174003402163e-12,\n",
       " 4.810469249605376e-07,\n",
       " 0.0034134825691580772,\n",
       " 6.5426377204858e-07,\n",
       " 4.266269115760224e-09,\n",
       " 4.90655565954512e-07,\n",
       " 1.4746324820957835e-12,\n",
       " 3.4131264925463256e-08,\n",
       " 2.1873815421718373e-13,\n",
       " 1.0137409426747674e-16,\n",
       " 3.362493953318335e-05,\n",
       " 1.3030351242449e-09,\n",
       " 5.3824687711312436e-06,\n",
       " 2.5970354755600056e-08,\n",
       " 7.31393328123886e-08,\n",
       " 1.0137240380458934e-08,\n",
       " 2.392166038589494e-07,\n",
       " 1.4293098615780764e-07,\n",
       " 2.1368117778669538e-12,\n",
       " 2.0691079498647014e-06,\n",
       " 1.7625612827032455e-06,\n",
       " 2.7436557631683502e-25,\n",
       " 4.6142573410179466e-05,\n",
       " 1.1272857092237132e-09,\n",
       " 9.198790340558816e-11,\n",
       " 0.0014808311825618148,\n",
       " 2.5571745609909158e-08,\n",
       " 1.2688842218697843e-13,\n",
       " 9.697743763581457e-08,\n",
       " 1.988322599285903e-14,\n",
       " 3.46727299649352e-11,\n",
       " 1.5218200506185442e-14,\n",
       " 9.458513083870912e-09,\n",
       " 4.0575637294537614e-10,\n",
       " 2.4243129333892955e-18,\n",
       " 1.1531368901066116e-16,\n",
       " 3.2078368406018853e-08,\n",
       " 3.491331881377846e-07,\n",
       " 1.9584582219844826e-11,\n",
       " 1.9216813029743207e-08,\n",
       " 2.156165468392146e-09,\n",
       " 3.03898097797628e-08,\n",
       " 1.175230636363267e-06,\n",
       " 4.359370087136938e-10,\n",
       " 3.0034617015672893e-09,\n",
       " 2.1514829306144845e-13,\n",
       " 9.667239737609634e-07,\n",
       " 1.2644800137517898e-11,\n",
       " 1.1887662765275309e-07,\n",
       " 1.4703628939405355e-11,\n",
       " 0.003554270137101412,\n",
       " 0.00015635351883247495,\n",
       " 1.5953711240968005e-08,\n",
       " 6.84849510435015e-10,\n",
       " 2.1622512669239313e-09,\n",
       " 3.03751301888866e-10,\n",
       " 1.1173419134369311e-10,\n",
       " 2.308034027009853e-06,\n",
       " 1.1447720105195458e-08,\n",
       " 3.9568999454786535e-06,\n",
       " 2.526204525565845e-07,\n",
       " 1.7498394981885212e-06,\n",
       " 1.2624163048258197e-07,\n",
       " 1.456237896491075e-06,\n",
       " 1.0454079268917837e-10,\n",
       " 2.0078192619621404e-07,\n",
       " 1.6969127193047632e-16,\n",
       " 4.465617564619606e-08,\n",
       " 0.00011524317233124748,\n",
       " 9.249029062630143e-06,\n",
       " 1.4538478199099814e-09,\n",
       " 2.6908001018455252e-05,\n",
       " 2.716246672029854e-10,\n",
       " 6.984210099147958e-09,\n",
       " 6.679417271916694e-17,\n",
       " 1.0346248018322513e-06,\n",
       " 1.4393776448518025e-10,\n",
       " 1.2300384235469641e-12,\n",
       " 3.6029692684208525e-12,\n",
       " 3.7045264078550133e-10,\n",
       " 3.1793803700885803e-12,\n",
       " 7.100415255756332e-10,\n",
       " 7.969692461529121e-09,\n",
       " 3.92566222584545e-11,\n",
       " 8.590446875979957e-14,\n",
       " 3.766171741332626e-14,\n",
       " 6.556293214998732e-07,\n",
       " 1.3203646509474254e-10,\n",
       " 3.851821292477631e-11,\n",
       " 1.879169063263267e-16,\n",
       " 7.149091648533945e-12,\n",
       " 1.0329905308026355e-05,\n",
       " 0.0014289910905063152,\n",
       " 7.85723219820511e-09,\n",
       " 2.1510405761281104e-13,\n",
       " 1.5335812047351238e-13,\n",
       " 5.8610795109175425e-22,\n",
       " 0.004041314125061035,\n",
       " 7.809557246218901e-06,\n",
       " 1.766774948919192e-05,\n",
       " 6.294302465903456e-07,\n",
       " 0.00022235643700696528,\n",
       " 6.4136690750005165e-12,\n",
       " 7.561702132508064e-12,\n",
       " 7.592870776562677e-10,\n",
       " 1.3660373179846808e-11,\n",
       " 2.5835747763380823e-08,\n",
       " 2.648564978446899e-10,\n",
       " 3.680921789595004e-09,\n",
       " 3.894463773690404e-08,\n",
       " 4.325235509377093e-14,\n",
       " 6.968971888454689e-08,\n",
       " 1.6161174828943636e-11,\n",
       " 9.955587786450448e-13,\n",
       " 2.1782600612141323e-08,\n",
       " 9.305513884703094e-18,\n",
       " 4.0481201724063e-11,\n",
       " 0.0016452217241749167,\n",
       " 8.611908061673113e-12,\n",
       " 0.00016572860477026552,\n",
       " 6.45707376456528e-10,\n",
       " 3.3848041014993e-13,\n",
       " 1.7512030020538916e-11,\n",
       " 1.0853930234588915e-06,\n",
       " 3.907331347363652e-09,\n",
       " 3.774057866887492e-17,\n",
       " 0.0011439189547672868,\n",
       " 8.369697990229241e-11,\n",
       " 1.2389429530733759e-18,\n",
       " 7.814249693183228e-05,\n",
       " 4.060258795846039e-09,\n",
       " 3.6225547006552006e-08,\n",
       " 2.6077862003148766e-07,\n",
       " 1.9135377442580648e-05,\n",
       " 1.3109941084110677e-11,\n",
       " 3.914394497428475e-08,\n",
       " 3.489331561468134e-07,\n",
       " 1.3113617569615599e-05,\n",
       " 3.350204025309722e-08,\n",
       " 4.004487053066441e-08,\n",
       " 6.450728687923402e-05,\n",
       " 1.4421329019853601e-08,\n",
       " 4.232591095387761e-07,\n",
       " 7.786866262904368e-07,\n",
       " 6.737806979018046e-10,\n",
       " 7.566754534960637e-15,\n",
       " 8.492077263611009e-09,\n",
       " 1.9415798746535984e-08,\n",
       " 3.199983495960623e-07,\n",
       " 7.010397894191556e-06,\n",
       " 1.9297954167996068e-06,\n",
       " 6.750461034243926e-05,\n",
       " 7.175133760028984e-06,\n",
       " 3.4910195936301014e-13,\n",
       " 3.003569615245283e-09,\n",
       " 6.6659193720397525e-09,\n",
       " 9.155507285640851e-08,\n",
       " 7.62136256882151e-11,\n",
       " 1.56492769747274e-05,\n",
       " 2.3620976286053974e-09,\n",
       " 7.293993832318754e-15,\n",
       " 0.0002915718068834394,\n",
       " 4.2565407198935645e-08,\n",
       " 3.250175240054887e-08,\n",
       " 6.584455695701763e-05,\n",
       " 4.547157317347228e-08,\n",
       " 1.3171478135090128e-17,\n",
       " 1.5253794061198533e-10,\n",
       " 5.387478196894335e-08,\n",
       " 0.00011072752386098728,\n",
       " 1.1203013627891778e-06,\n",
       " 0.000102166501164902,\n",
       " 2.8825240805385732e-12,\n",
       " 2.232050988482115e-09,\n",
       " 6.491945441666758e-06,\n",
       " 4.155060196353588e-06,\n",
       " 3.1979243431123905e-06,\n",
       " 8.584502886321843e-09,\n",
       " 1.4132912776274736e-13,\n",
       " 8.701620686224487e-07,\n",
       " 2.4742647167230736e-11,\n",
       " 3.4823003147721465e-07,\n",
       " 5.288315492180118e-07,\n",
       " 1.4058018678042572e-06,\n",
       " 0.00042205528006888926,\n",
       " 0.0011664265766739845,\n",
       " 1.3913651342178923e-09,\n",
       " 0.013923998922109604,\n",
       " 5.090104736088421e-16,\n",
       " 2.3775744726142484e-15,\n",
       " 0.0003780361730605364,\n",
       " 2.6212547687975984e-09,\n",
       " 1.5284089727174432e-07,\n",
       " 2.414891420512988e-12,\n",
       " 3.502116374676234e-09,\n",
       " 2.6193151380499158e-12,\n",
       " 2.7391086405259557e-05,\n",
       " 2.5119817337326822e-08,\n",
       " 3.2700731935619842e-06,\n",
       " 3.1478446151783634e-12,\n",
       " 5.660781156433155e-14,\n",
       " 9.501824511665841e-14,\n",
       " 3.2632693769407695e-10,\n",
       " 5.5494952383439156e-11,\n",
       " 1.175768034045177e-07,\n",
       " 2.617628354073531e-07,\n",
       " 5.924079360397627e-08,\n",
       " 3.538474629749544e-05,\n",
       " 1.179876889523257e-07,\n",
       " 1.367777895211475e-05,\n",
       " 3.8169547522670655e-09,\n",
       " 2.374912766445192e-12,\n",
       " 1.0884319162109135e-13,\n",
       " 2.517051152873878e-15,\n",
       " 4.090865146633149e-11,\n",
       " 5.476035269680324e-08,\n",
       " 1.014401958211895e-19,\n",
       " 3.2376626677432796e-06,\n",
       " 6.162488261907129e-07,\n",
       " 3.8844638616808425e-09,\n",
       " 6.400513452575751e-10,\n",
       " 1.986365987249883e-07,\n",
       " 0.0004391775873955339,\n",
       " 1.1304001484857551e-10,\n",
       " 4.578593575388368e-07,\n",
       " 3.7008243691794007e-10,\n",
       " 4.360834360284116e-09,\n",
       " 4.0411000554740895e-06,\n",
       " 3.868055615391386e-12,\n",
       " 6.050269803381525e-05,\n",
       " 5.654613496192118e-12,\n",
       " 7.558235287641324e-12,\n",
       " 5.126637656061028e-11,\n",
       " 5.11713800221969e-08,\n",
       " 6.868028322060127e-06,\n",
       " 5.30612793286922e-12,\n",
       " 6.491090971394442e-06,\n",
       " 2.5734039343916493e-09,\n",
       " 0.7084477543830872,\n",
       " 8.875798762630893e-09,\n",
       " 6.121014112236978e-11,\n",
       " 5.6426870287396014e-08,\n",
       " 3.3473307459175317e-10,\n",
       " 9.778148069017334e-09,\n",
       " 8.755138371826631e-15,\n",
       " 4.7730030928505585e-05,\n",
       " 1.154031425976143e-09,\n",
       " 1.359762020862465e-12,\n",
       " 7.464043272342735e-10,\n",
       " 4.240744965500198e-05,\n",
       " 2.5768448139174005e-11,\n",
       " 1.2870650323293376e-08,\n",
       " 4.333915225394197e-15,\n",
       " 7.1739877967047505e-06,\n",
       " 1.4156469399506655e-11,\n",
       " 1.5812340325993546e-09,\n",
       " 3.2785351322672796e-08,\n",
       " 1.4293581873658923e-09,\n",
       " 0.0001169450770248659,\n",
       " 1.564988373267684e-12,\n",
       " 7.513485056424287e-16,\n",
       " 4.187993894955383e-15,\n",
       " 2.2392147513983218e-07,\n",
       " 2.690738907726309e-12,\n",
       " 4.148536236758815e-10,\n",
       " 1.6042070782873452e-08,\n",
       " 0.079677052795887,\n",
       " 1.4128256724255106e-11,\n",
       " 4.3675225111852733e-13,\n",
       " 1.0608870582018426e-07,\n",
       " 1.9506501969246415e-10,\n",
       " 5.963824634136472e-08,\n",
       " 1.8978857385405085e-13,\n",
       " 7.109346370270941e-06,\n",
       " 1.6381876832838316e-07,\n",
       " 7.684892722181758e-10,\n",
       " 2.855193905197846e-15,\n",
       " 3.600357859068204e-11,\n",
       " 5.847973066084103e-14,\n",
       " 2.427671128360509e-12,\n",
       " 1.2744780178763904e-05,\n",
       " 3.52931306224491e-06,\n",
       " 1.11254685464246e-07,\n",
       " 4.420491403478444e-11,\n",
       " 6.227439354120068e-13,\n",
       " 8.24176815683586e-09,\n",
       " 0.0003168624243699014,\n",
       " 6.590485490676201e-09,\n",
       " 3.032538413091923e-12,\n",
       " 1.8641138632702337e-10,\n",
       " 3.717394447821931e-12,\n",
       " 1.7573215416177845e-07,\n",
       " 5.406790873309017e-14,\n",
       " 5.913092536502518e-06,\n",
       " 8.774801818180666e-16,\n",
       " 3.029371753449084e-10,\n",
       " 1.3897231976311986e-10,\n",
       " 0.006961708422750235,\n",
       " 2.0152127078176818e-08,\n",
       " 1.5292315211443835e-13,\n",
       " 6.0873039193967e-16,\n",
       " 3.3026449131057234e-08,\n",
       " 1.6496471744176233e-06,\n",
       " 7.038647709123325e-08,\n",
       " 1.1492474749630333e-09,\n",
       " 1.7170879829109253e-08,\n",
       " 4.5646185498071645e-08,\n",
       " 1.0998092627584333e-12,\n",
       " 6.83265781193515e-13,\n",
       " 7.303462439267605e-07,\n",
       " 6.06446405981842e-07,\n",
       " 3.849307539383062e-10,\n",
       " 3.4407240945277806e-10,\n",
       " 6.0372149164322764e-05,\n",
       " 6.834350307904913e-10,\n",
       " 2.022929947997909e-06,\n",
       " 1.4347519616819682e-08,\n",
       " 1.5689517740558045e-10,\n",
       " 9.109527923101268e-07,\n",
       " 1.8615912145136804e-09,\n",
       " 7.805350833223201e-06,\n",
       " 6.148080933243705e-10,\n",
       " 2.4373008056244316e-09,\n",
       " 7.683858882501227e-08,\n",
       " 1.5384225143799668e-11,\n",
       " 1.1769799024285987e-10,\n",
       " 1.4881736251290412e-12,\n",
       " 1.2863135556706595e-10,\n",
       " 1.0984765834708707e-15,\n",
       " 4.5073886667523766e-07,\n",
       " 2.32457338711356e-07,\n",
       " 3.7648418996054367e-13,\n",
       " 3.6476242257776903e-06,\n",
       " 3.973959792347159e-07,\n",
       " 2.1938094008078224e-08,\n",
       " 1.7118537219262125e-13,\n",
       " 2.00528546656642e-07,\n",
       " 2.0212663487395588e-10,\n",
       " 1.3539408882934367e-07,\n",
       " 3.55182159725298e-12,\n",
       " 3.6625872326112585e-06,\n",
       " 1.8226517300642953e-13,\n",
       " 4.149566541072902e-12,\n",
       " 6.28708266003919e-11,\n",
       " 2.463989630996366e-06,\n",
       " 7.096412559803866e-07,\n",
       " 3.0442834031418897e-06,\n",
       " 0.0019317840924486518,\n",
       " 5.267032296418783e-11,\n",
       " 7.143702235388582e-15,\n",
       " 2.074684516628622e-06,\n",
       " 4.122483460378135e-06,\n",
       " 0.00011852601892314851,\n",
       " 1.8374088361916563e-10,\n",
       " 1.8932785224023974e-06,\n",
       " 2.4334298132089316e-07,\n",
       " 0.002100158017128706,\n",
       " 4.866998537522704e-08,\n",
       " 1.394385584774227e-08,\n",
       " 6.931185486669378e-11,\n",
       " 1.3163335699228895e-10,\n",
       " 4.3640902003261317e-10,\n",
       " 5.404408587317278e-10,\n",
       " 1.7846357724948803e-09,\n",
       " 6.887955805723323e-07,\n",
       " 9.601710533157625e-15,\n",
       " 0.0030671905260533094,\n",
       " 1.480594562508486e-07,\n",
       " 3.8749053607716605e-14,\n",
       " 1.3178133063951325e-11,\n",
       " 1.346359022136312e-05,\n",
       " 1.2336326404849274e-10,\n",
       " 1.3481620442234998e-07,\n",
       " 3.153380748699419e-05,\n",
       " 4.23744960764672e-16,\n",
       " 9.53268783354666e-11,\n",
       " 1.2840694653404316e-11,\n",
       " 1.8398029766331092e-08,\n",
       " 3.2980949526972836e-07,\n",
       " 2.2372713459617444e-08,\n",
       " 6.377821049063925e-10,\n",
       " 8.678228627248888e-14,\n",
       " 3.7079396975059353e-07,\n",
       " 0.0006575794541276991,\n",
       " 4.454010991139512e-07,\n",
       " 1.4666886727354722e-07,\n",
       " 5.402201281867747e-07,\n",
       " 3.5768003670000326e-08,\n",
       " 4.59756188675442e-09,\n",
       " 2.7214848614676157e-06,\n",
       " 3.881568460747942e-14,\n",
       " 1.3765664164111513e-08,\n",
       " 1.2697204399003681e-11,\n",
       " 1.3394687137235906e-08,\n",
       " 4.330978242705896e-08,\n",
       " 0.0015595300355926156,\n",
       " 5.3628931157012616e-11,\n",
       " 3.0672098975254025e-12,\n",
       " 3.1683180384822762e-12,\n",
       " 4.701627403846942e-06,\n",
       " 3.130685988228521e-10,\n",
       " 8.232555082088311e-09,\n",
       " 1.8529784938436933e-05,\n",
       " 3.2508784553186842e-09,\n",
       " 0.0017377464100718498,\n",
       " 5.049708988735802e-07,\n",
       " 0.00694155553355813,\n",
       " 8.014322361304949e-08,\n",
       " 1.1983861842423244e-16,\n",
       " 2.0282735435178624e-15,\n",
       " 5.78911094409329e-12,\n",
       " 5.4239206875861257e-11,\n",
       " 1.3497149895600218e-17,\n",
       " 6.880432855405072e-12,\n",
       " 1.2830538253183477e-05,\n",
       " 4.317627628851444e-15,\n",
       " 1.8539266122274967e-08,\n",
       " 4.542777332972037e-06,\n",
       " 1.5007067810657304e-09,\n",
       " 1.4186817276495844e-09,\n",
       " 3.3871451650402395e-14,\n",
       " 4.00520639232127e-06,\n",
       " 2.0884747585297146e-14,\n",
       " 1.7908172503505043e-13,\n",
       " 1.0759824142780872e-08,\n",
       " 2.7263944435418352e-09,\n",
       " 2.420089003862813e-06,\n",
       " 2.683969990702195e-10,\n",
       " 0.00027384504210203886,\n",
       " 2.786715231195558e-05,\n",
       " 3.381128621526841e-08,\n",
       " 1.8656874090083875e-07,\n",
       " 2.746226163141685e-11,\n",
       " 2.7544392005966756e-13,\n",
       " 8.253649430578491e-10,\n",
       " 4.404094276766468e-12,\n",
       " 4.873781521084737e-16,\n",
       " 1.3237956737743861e-12,\n",
       " 2.1018702985825048e-20,\n",
       " 0.0010315657127648592,\n",
       " 1.787154625676468e-11,\n",
       " 3.0078684432055525e-08,\n",
       " 2.0058257138577673e-11,\n",
       " 2.9475890617192135e-09,\n",
       " 2.348317617126395e-17,\n",
       " 2.808639765206067e-09,\n",
       " 5.203845375945093e-06,\n",
       " 3.3250838527010274e-08,\n",
       " 7.729943352074997e-10,\n",
       " 6.055700103695105e-14,\n",
       " 1.9503431758494116e-06,\n",
       " 1.187253459988824e-07,\n",
       " 1.0140515094292368e-09,\n",
       " 8.663279004395008e-05,\n",
       " 4.262966646351174e-10,\n",
       " 0.0009718945948407054,\n",
       " 5.360371521656582e-11,\n",
       " 7.626066287871049e-20,\n",
       " 5.485244962237512e-13,\n",
       " 5.8831428617622805e-08,\n",
       " 0.017182251438498497,\n",
       " 1.0310469811258827e-08,\n",
       " 1.576786062829072e-10,\n",
       " 7.496966532016813e-07,\n",
       " 3.112041223676809e-12,\n",
       " 7.887087094538003e-10,\n",
       " 4.735733680205634e-11,\n",
       " 0.00541993323713541,\n",
       " 2.343938540168896e-14,\n",
       " 3.117799496976659e-05,\n",
       " 1.494426840054075e-07,\n",
       " 2.902031822861024e-17,\n",
       " 2.4809271303993796e-10,\n",
       " 5.036533252678055e-07,\n",
       " 2.904463514141753e-08,\n",
       " 5.931610758125316e-10,\n",
       " 1.4820153104722067e-08,\n",
       " 6.645631852979228e-13,\n",
       " 2.6877473580100286e-09,\n",
       " 1.1340310362773313e-17,\n",
       " 2.604581758873948e-14,\n",
       " 4.95230549277248e-12,\n",
       " 1.1692371117533185e-05,\n",
       " 8.553458497040367e-10,\n",
       " 1.866753152057754e-08,\n",
       " 1.238850302343053e-07,\n",
       " 6.182379744674912e-18,\n",
       " 5.773651719209738e-05,\n",
       " 9.308155313192401e-07,\n",
       " 8.561510611571066e-08,\n",
       " 4.867516112394554e-12,\n",
       " 6.663909880444407e-05,\n",
       " 3.9621674829959375e-08,\n",
       " 4.0292590597346134e-07,\n",
       " 3.2998104249060134e-09,\n",
       " 1.5952804460539483e-05,\n",
       " 4.017224910057848e-06,\n",
       " 8.869240275544144e-08,\n",
       " 4.598754458129406e-06,\n",
       " 6.922518808183398e-11,\n",
       " 1.5399669791804627e-05,\n",
       " 4.6557516175660396e-10,\n",
       " 8.647748073187245e-10,\n",
       " 6.327782742232557e-10,\n",
       " 1.856149174273014e-05,\n",
       " 5.014000326042378e-10,\n",
       " 3.860501692543039e-06,\n",
       " 2.6513132979744114e-05,\n",
       " 6.982871525451628e-08,\n",
       " 8.857526268002403e-09,\n",
       " 1.5474618114685867e-12,\n",
       " 2.0846544976360626e-11,\n",
       " 1.1712087966131435e-09,\n",
       " 0.0010625239228829741,\n",
       " 2.6369644245960444e-09,\n",
       " 6.782229320378974e-06,\n",
       " 1.1138326954096556e-05,\n",
       " 3.015938887518388e-10,\n",
       " 3.6147350303966652e-12,\n",
       " 7.174619440775132e-07,\n",
       " 3.913147884304635e-05,\n",
       " 0.0005993525264784694,\n",
       " 2.752409758444152e-11,\n",
       " 3.5468243453351533e-08,\n",
       " 6.040247626515338e-07,\n",
       " 3.717968013461359e-07,\n",
       " 1.2927829640130284e-10,\n",
       " 1.538376937464075e-17,\n",
       " 1.1480022976684268e-07,\n",
       " 2.278754268614236e-11,\n",
       " 7.959968684190244e-08,\n",
       " 1.4370675482933137e-10,\n",
       " 1.2747623052630774e-12,\n",
       " 1.4990145236204455e-10,\n",
       " 1.0259526561640087e-07,\n",
       " 2.9432232651060986e-08,\n",
       " 2.815389166244131e-07,\n",
       " 1.7002067806970445e-06,\n",
       " 3.029771800198283e-14,\n",
       " 0.007520394865423441,\n",
       " 0.0003400275018066168,\n",
       " 9.984012921959717e-11,\n",
       " 4.2751653950290347e-07,\n",
       " 3.5448150491335095e-12,\n",
       " 1.4026483974305393e-08,\n",
       " 2.774904528379807e-09,\n",
       " 2.439759765743288e-12,\n",
       " 1.9352669369254727e-06,\n",
       " 1.3361250474075437e-11,\n",
       " 4.232192623021547e-06,\n",
       " 1.0756200197192811e-07,\n",
       " 4.4337909343994397e-07,\n",
       " 1.1757867213191275e-07,\n",
       " 1.671634011768397e-11,\n",
       " 8.975109267339576e-06,\n",
       " 3.6497059596740655e-08,\n",
       " 4.4364751872194574e-09,\n",
       " 1.7537139546542485e-13,\n",
       " 3.303982506778835e-16,\n",
       " 7.612753449848242e-08,\n",
       " 3.4599541114122e-12,\n",
       " 9.717928683983246e-09,\n",
       " 2.6453887969069e-09,\n",
       " 8.719615199152819e-13,\n",
       " 6.7671397374624576e-09,\n",
       " 3.2519674277864397e-05,\n",
       " 4.882921150750619e-11,\n",
       " 2.5580080276199624e-08,\n",
       " 0.0001194638607557863,\n",
       " 1.8523344242195403e-15,\n",
       " 1.7624109171389703e-19,\n",
       " 2.0100654474219937e-10,\n",
       " 3.575469698091638e-09,\n",
       " 2.038871294018918e-08,\n",
       " 1.0086823749588802e-05,\n",
       " 0.009061542339622974,\n",
       " 6.341213065752527e-07,\n",
       " 1.3833657830364388e-10,\n",
       " 8.687854987287844e-14,\n",
       " 5.918928422943281e-07,\n",
       " 6.963481951061112e-07,\n",
       " 8.733214781386778e-05,\n",
       " 4.278201057306141e-12,\n",
       " 5.035853400947587e-10,\n",
       " 7.810291996479535e-11,\n",
       " 4.776034012721198e-10,\n",
       " 8.76488748247084e-09,\n",
       " 5.367276845191782e-09,\n",
       " 4.21961181273911e-11,\n",
       " 1.62749711307697e-05,\n",
       " 2.1998718402471695e-09,\n",
       " 1.374012570387606e-09,\n",
       " 2.954021359122261e-12,\n",
       " 1.330994620074577e-10,\n",
       " 6.100525900415432e-13,\n",
       " 3.168205420234216e-10,\n",
       " 6.311910993872516e-09,\n",
       " 2.929206210922075e-08,\n",
       " 0.0003822875441983342,\n",
       " 1.1663268573158803e-08,\n",
       " 2.5429403526015972e-18,\n",
       " 1.7729752128242682e-12,\n",
       " 1.8725028716167283e-14,\n",
       " 2.973524360072588e-08,\n",
       " 6.2807416725263465e-06,\n",
       " 5.853378581832658e-08,\n",
       " 1.185621794773896e-16,\n",
       " 2.1864252630621195e-09,\n",
       " 1.8918228761322098e-08,\n",
       " 1.3471572815615396e-11,\n",
       " 1.3878999945843296e-12,\n",
       " 4.9616463826396284e-08,\n",
       " 4.180578994095185e-09,\n",
       " 0.000302325701341033,\n",
       " 1.0898349280322184e-12,\n",
       " 1.0617165327399246e-22,\n",
       " 1.9426359132435067e-10,\n",
       " 1.1022289982065558e-05,\n",
       " 3.201102458660898e-07,\n",
       " 3.601412856824027e-08,\n",
       " 2.5289470170775097e-11,\n",
       " 4.926441121710923e-08,\n",
       " 3.478290722114252e-08,\n",
       " 2.2989178919893827e-13,\n",
       " 3.686866079360279e-13,\n",
       " 1.0108565731432179e-13,\n",
       " 1.0955925403011157e-11,\n",
       " 2.850253366659672e-09,\n",
       " 3.0520565241776154e-11,\n",
       " 2.948718095156864e-16,\n",
       " 6.348645280135593e-23,\n",
       " 5.534536103368737e-05,\n",
       " 1.3714532087760745e-06,\n",
       " 1.0122366802534088e-05,\n",
       " 2.5915180685842643e-06,\n",
       " 1.0453397408127785e-05,\n",
       " 5.43612030390328e-12,\n",
       " 5.592659321762561e-11,\n",
       " 1.3980764324017514e-09,\n",
       " 2.8219599101930726e-08,\n",
       " 1.0730007993231538e-09,\n",
       " 2.482422785011452e-17,\n",
       " 6.057330756448209e-05,\n",
       " 0.003785825567319989,\n",
       " 3.5500634550100774e-12,\n",
       " 2.769872911695631e-15,\n",
       " 5.0914930049827944e-09,\n",
       " 3.002989176770221e-11,\n",
       " 8.38208896822984e-14,\n",
       " 4.693166428398898e-12,\n",
       " 2.9584589356090873e-07,\n",
       " 5.865728326170938e-06,\n",
       " 3.028668427162984e-10,\n",
       " 2.484985328621292e-09,\n",
       " 6.537790274430133e-12,\n",
       " 2.4657609287714877e-08,\n",
       " 2.1372489888982216e-10,\n",
       " 3.5020966606680304e-05,\n",
       " 0.00019962301303166896,\n",
       " 1.8947508007016722e-09,\n",
       " 9.809522985571029e-13,\n",
       " 1.5684918253100477e-07,\n",
       " 2.40891968132928e-05,\n",
       " 2.1443492315142976e-08,\n",
       " 2.434812351737037e-09,\n",
       " 5.101657052364317e-08,\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_class_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529daf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3542c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02261dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011cd9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
